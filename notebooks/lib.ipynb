{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Ri0n6vDgWC",
        "outputId": "738f823d-0239-456d-bec5-c2e5b8917a0d"
      },
      "id": "k1Ri0n6vDgWC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ccc8a4d8-e682-4765-b140-277eaa795ff6",
      "metadata": {
        "id": "ccc8a4d8-e682-4765-b140-277eaa795ff6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "3dad5633-a008-453e-9a77-ce1faeea73ed",
      "metadata": {
        "id": "3dad5633-a008-453e-9a77-ce1faeea73ed"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Literal\n",
        "\n",
        "class BracketAccess(type):\n",
        "\n",
        "    \"\"\"\n",
        "    A metaclass that enables bracket notation for attribute access in its classes.\n",
        "\n",
        "    Classes that use this metaclass can access their attributes using brackets ([]),\n",
        "    like dictionary objects, instead of the conventional dot (.) notation.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    key : str\n",
        "        The attribute name that is being accessed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(cls, key: str):\n",
        "\n",
        "        \"\"\"\n",
        "        Retrieve an attribute of the class using bracket notation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        key : str\n",
        "            The attribute name that is being accessed.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        The attribute's value, if it exists; otherwise, `None`.\n",
        "        \"\"\"\n",
        "        return getattr(cls, key, None)\n",
        "\n",
        "class SampleMethods(metaclass=BracketAccess):\n",
        "\n",
        "    \"\"\"\n",
        "    A collection of methods for generating random datasets and processing them.\n",
        "    The class uses the BracketAccess metaclass to allow bracket notation for method access.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    noise(scale: float, num_time_steps: int) -> np.ndarray\n",
        "        Generate a random noise dataset.\n",
        "\n",
        "    brownian_motion(num_time_steps: int, initial_value: int, drift=0.0,\n",
        "                    volatility=1.0, dt=1.0) -> np.ndarray\n",
        "        Generate a Brownian motion path.\n",
        "\n",
        "    random_oscillator(uniform_range: Tuple[int], num_time_steps: int) -> np.ndarray\n",
        "        Generate a random oscillator dataset.\n",
        "\n",
        "    standardize(input_array: np.ndarray) -> np.ndarray\n",
        "        Standardize an array.\n",
        "\n",
        "    normalize(input_array: np.ndarray) -> np.ndarray\n",
        "        Normalize an array.\n",
        "\n",
        "    random_dataset(n_series: int,\n",
        "                   series_types: List[Literal['noise', 'brownian_motion', 'random_oscillator']]) -> pd.DataFrame\n",
        "        Generate a DataFrame of random datasets of specified types.\n",
        "\n",
        "    all() -> List[str]\n",
        "        Get a list of all public methods.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def noise(scale: float,\n",
        "              num_time_steps: int,\n",
        "              **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate a random noise dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        scale : float\n",
        "            The standard deviation of the normal distribution.\n",
        "        num_time_steps : int\n",
        "            The number of time steps.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The generated random noise.\n",
        "        \"\"\"\n",
        "        return np.random.normal(scale=scale, size=num_time_steps)\n",
        "\n",
        "    @staticmethod\n",
        "    def brownian_motion(num_time_steps: int,\n",
        "                        initial_value: int,\n",
        "                        drift=0.0,\n",
        "                        volatility=1.0,\n",
        "                        dt=1.0,\n",
        "                        **kwargs):\n",
        "\n",
        "        \"\"\"\n",
        "        Generate a Brownian motion path.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        num_time_steps : int\n",
        "            The number of time steps.\n",
        "        initial_value : int\n",
        "            The initial value of the path.\n",
        "        drift : float, optional\n",
        "            The drift of the Brownian motion, by default 0.0.\n",
        "        volatility : float, optional\n",
        "            The volatility of the Brownian motion, by default 1.0.\n",
        "        dt : float, optional\n",
        "            The time step size, by default 1.0.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The generated Brownian motion path.\n",
        "        \"\"\"\n",
        "\n",
        "        increments = np.random.normal(loc=drift*dt, scale=volatility*np.sqrt(dt), size=num_time_steps)\n",
        "\n",
        "        # Generate forward Brownian motion path\n",
        "        path = np.cumsum(increments) + initial_value\n",
        "\n",
        "        return path\n",
        "\n",
        "    @staticmethod\n",
        "    def random_oscillator(uniform_range: Tuple[int],\n",
        "                          num_time_steps: int,\n",
        "                          **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate a random oscillator dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        uniform_range : Tuple[int]\n",
        "            The range of the uniform distribution to draw from.\n",
        "        num_time_steps : int\n",
        "            The number of time steps.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The generated random oscillator.\n",
        "        \"\"\"\n",
        "\n",
        "        return np.cos(np.random.uniform(*uniform_range, num_time_steps))\n",
        "\n",
        "    @staticmethod\n",
        "    def standardize(input_array: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        \"\"\"\n",
        "        Standardize an array.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_array : np.ndarray\n",
        "            The input array.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The standardized array.\n",
        "        \"\"\"\n",
        "\n",
        "        return (input_array - input_array.mean())/input_array.std()\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize(input_array: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        \"\"\"\n",
        "        Normalize an array.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_array : np.ndarray\n",
        "            The input array.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The normalized array.\n",
        "        \"\"\"\n",
        "\n",
        "        return (input_array - input_array.min())/(input_array.max()-input_array.min())\n",
        "\n",
        "    @staticmethod\n",
        "    def random_dataset(n_series: int,\n",
        "                       series_types: List[Literal['noise', 'brownian_motion', 'random_oscillator']],\n",
        "                       **kwargs) -> pd.DataFrame:\n",
        "\n",
        "        \"\"\"\n",
        "        Generate a DataFrame of random datasets of specified types.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_series : int\n",
        "            The number of series to generate.\n",
        "        series_types : List[Literal['noise', 'brownian_motion', 'random_oscillator']]\n",
        "            The types of series to generate.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            The DataFrame of generated datasets.\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(series_types) == n_series, AssertionError('len(series_types) must be equal to n_series')\n",
        "        for name in series_types:\n",
        "            assert name in ['noise', 'brownian_motion', 'random_oscillator'], AssertionError(f\"{name} must be one of ['noise', 'brownian_motion', 'ranom_oscillator']\")\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        for a, name in enumerate(series_types):\n",
        "            data = SampleMethods[name](**kwargs)\n",
        "\n",
        "            if 'transform' in kwargs.keys():\n",
        "                match kwargs['transform']:\n",
        "                    case 'normalize':\n",
        "                        data = SampleMethods.normalize(data)\n",
        "                    case 'standardize':\n",
        "                        data = SampleMethods.standardize(data)\n",
        "                    case other:\n",
        "                        pass\n",
        "\n",
        "            dataset[f\"{name}_{a}\"] = data\n",
        "\n",
        "        return pd.DataFrame(dataset)\n",
        "\n",
        "    @staticmethod\n",
        "    def all() -> List[str]:\n",
        "\n",
        "        \"\"\"\n",
        "        Get a list of all public methods.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[str]\n",
        "            The list of all public methods.\n",
        "        \"\"\"\n",
        "\n",
        "        return [key for key in SampleMethods.__dict__.keys() if not key.startswith('_')][:-1]\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b0b8ee24-69e4-4ec5-bd52-475b10654057",
      "metadata": {
        "id": "b0b8ee24-69e4-4ec5-bd52-475b10654057"
      },
      "outputs": [],
      "source": [
        "class WindowTransform(metaclass=BracketAccess):\n",
        "    \"\"\"\n",
        "    A class for transforming 1D data into a 2D representation using window methods.\n",
        "    The class uses the BracketAccess metaclass to allow bracket notation for method access.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    sliding_window(df: pd.DataFrame, window_length: int) -> np.ndarray\n",
        "        Create a sliding window view of the input DataFrame.\n",
        "\n",
        "    non_overlapping_window(df: pd.DataFrame, window_length: int) -> np.ndarray\n",
        "        Create a non-overlapping window view of the input DataFrame.\n",
        "\n",
        "    all() -> List[str]\n",
        "        Get a list of all public methods.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def sliding_window(df: pd.DataFrame, window_length: int):\n",
        "        \"\"\"\n",
        "        Create a sliding window view of the input DataFrame.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            The input DataFrame.\n",
        "        window_length : int\n",
        "            The length of the window.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The 2D array of the sliding window view.\n",
        "        \"\"\"\n",
        "        sw = np.squeeze(np.lib.stride_tricks.sliding_window_view(df.values, (window_length,df.shape[-1])))\n",
        "        return np.swapaxes(sw, 1,-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def non_overlapping_window(df: pd.DataFrame, window_length: int):\n",
        "        \"\"\"\n",
        "        Create a non-overlapping window view of the input DataFrame.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            The input DataFrame.\n",
        "        window_length : int\n",
        "            The length of the window.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The 2D array of the non-overlapping window view.\n",
        "        \"\"\"\n",
        "        idxs = np.arange(df.shape[0]//window_length) * window_length\n",
        "        stacked = np.dstack([df.iloc[idx:idx+window_length].values for idx in idxs])\n",
        "        return np.swapaxes(stacked, 0,-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def all():\n",
        "        \"\"\"\n",
        "        Get a list of all public methods.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[str]\n",
        "            The list of all public methods.\n",
        "        \"\"\"\n",
        "        return [key for key in WindowTransform.__dict__.keys() if not key.startswith('_')][:-1]\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40b98738-7711-4bcb-a4c5-12470e69cd77",
      "metadata": {
        "id": "40b98738-7711-4bcb-a4c5-12470e69cd77"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "c397a128-b327-4a58-9014-db108b4b4ccd",
      "metadata": {
        "id": "c397a128-b327-4a58-9014-db108b4b4ccd"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultivariateDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A class for turning a DataFrame of series into multivariate multiple (windowed) time series datasets,\n",
        "    of given chunk sizes. The class inherits from PyTorch's Dataset class.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __new__(cls, mode: Literal['sliding_window', 'non_overlapping_window'], df: pd.DataFrame,\n",
        "            window_length: int, transform=None) -> 'MultivariateDataset'\n",
        "        Create a new instance of the class.\n",
        "\n",
        "    __init__(self, mode: Literal['sliding_window', 'non_overlapping_window'], df: pd.DataFrame,\n",
        "             window_length: int, transform=None)\n",
        "        Initialize the instance.\n",
        "\n",
        "    __len__(self) -> int\n",
        "        Get the length of the dataset.\n",
        "\n",
        "    __getitem__(self, index) -> torch.Tensor\n",
        "        Get an item from the dataset.\n",
        "    \"\"\"\n",
        "    def __new__(cls,\n",
        "                mode: Literal['sliding_window', 'non_overlapping_window'],\n",
        "                df: pd.DataFrame,\n",
        "                window_length: int,\n",
        "                transform=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Create a new instance of the class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : Literal['sliding_window', 'non_overlapping_window']\n",
        "            The window mode.\n",
        "        df : pd.DataFrame\n",
        "            The input DataFrame.\n",
        "        window_length : int\n",
        "            The length of the window.\n",
        "        transform : callable, optional\n",
        "            The transform to apply to the data.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        MultivariateDataset\n",
        "            The new instance of the class.\n",
        "        \"\"\"\n",
        "\n",
        "        assert mode in WindowTransform.all(), AssertionError(f'mode must be on of {WindowTransform.methods()}')\n",
        "\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self,\n",
        "                 mode: Literal['sliding_window', 'non_overlapping_window'],\n",
        "                 df: pd.DataFrame,\n",
        "                 window_length: int,\n",
        "                 transform=None) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : Literal['sliding_window', 'non_overlapping_window']\n",
        "            The window mode.\n",
        "        df : pd.DataFrame\n",
        "            The input DataFrame.\n",
        "        window_length : int\n",
        "            The length of the window.\n",
        "        transform : callable, optional\n",
        "            The transform to apply to the data.\n",
        "        \"\"\"\n",
        "\n",
        "        global DEVICE\n",
        "\n",
        "        self.tensors = torch.FloatTensor(WindowTransform[mode](df, window_length)).to(DEVICE)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the length of the dataset.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            The length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.tensors)\n",
        "\n",
        "    def __getitem__(self, index) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Get an item from the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        index : int\n",
        "            The index of the item.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The item from the dataset.\n",
        "        \"\"\"\n",
        "        sample = self.tensors[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transofrm(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "85463067-a17c-4f0b-95aa-1d392d5b2e0b",
      "metadata": {
        "id": "85463067-a17c-4f0b-95aa-1d392d5b2e0b"
      },
      "outputs": [],
      "source": [
        "DF = SampleMethods.random_dataset(9, ['random_oscillator','random_oscillator','random_oscillator','brownian_motion','brownian_motion','brownian_motion','noise','noise','noise'], uniform_range=(0,1), num_time_steps=830*2880, initial_value=100, scale=0.5, transform='standardize')\n",
        "SAMPLE_DATASET = MultivariateDataset('non_overlapping_window', DF, 2880)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "4ba2ff61-c9f0-4b9d-a880-92c1db64b713",
      "metadata": {
        "id": "4ba2ff61-c9f0-4b9d-a880-92c1db64b713"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.modules.transformer import MultiheadAttention\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Original inspiration: https://arxiv.org/pdf/2303.07048, credits to Borui Cai, Shuiqiao Yang, Longxiang Gao, Yong Xiang\n",
        "    Implementational changes: LeakyReLU instead of ReLu for conv transpose layers, customized number of layers, upsampling in Decoder.\n",
        "\n",
        "    Encoder class for a Variational Autoencoder (VAE) Neural Network.\n",
        "    Inherits from PyTorch's nn.Module class.\n",
        "\n",
        "    The encoder applies a series of convolutional layers, a multi-head self-attention mechanism,\n",
        "    and fully connected layers to output the mean and standard deviation vectors for the VAE's latent space.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, input_dim, conv_filters, conv_kernel_size, conv_strides, attention_heads, latent_dim)\n",
        "        Initialize the instance.\n",
        "\n",
        "    add_conv_layer(self, in_channels, out_channels, kernel_size, stride)\n",
        "        Add a convolutional layer followed by a ReLU activation to the encoder.\n",
        "\n",
        "    forward(self, x) -> Tuple[torch.Tensor, torch.Tensor]\n",
        "        Forward pass through the encoder.\n",
        "\n",
        "    reparameterize(self, mu, logvar) -> torch.Tensor\n",
        "        Generate a random sample from the distribution defined by mu and logvar.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 conv_filters: Sequence[int],\n",
        "                 conv_kernel_size: Sequence[int],\n",
        "                 conv_strides: Sequence[int],\n",
        "                 attention_heads:int,\n",
        "                 latent_dim:int) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim : int\n",
        "            The dimension of the input data.\n",
        "        conv_filters : List[int]\n",
        "            The number of filters for each convolutional layer.\n",
        "        conv_kernel_size : List[int]\n",
        "            The kernel size for each convolutional layer.\n",
        "        conv_strides : List[int]\n",
        "            The stride for each convolutional layer.\n",
        "        attention_heads : int\n",
        "            The number of attention heads for the multi-head self-attention mechanism.\n",
        "        latent_dim : int\n",
        "            The dimension of the latent space.\n",
        "        \"\"\"\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # Initialize lists for convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "\n",
        "        # Add convolutional layers\n",
        "        for i in range(len(conv_filters)):\n",
        "            self.add_conv_layer(input_dim if i==0 else conv_filters[i-1],\n",
        "                                conv_filters[i], conv_kernel_size[i], conv_strides[i])\n",
        "\n",
        "        # Multi-head self-attention mechanism\n",
        "        self.self_attention = MultiheadAttention(embed_dim=conv_filters[-1], num_heads=attention_heads)\n",
        "\n",
        "        # Fully connected layers to output the mean and standard deviation vectors\n",
        "        self.fc_mu = nn.Linear(conv_filters[-1], latent_dim)\n",
        "        self.fc_logvar = nn.Linear(conv_filters[-1], latent_dim)\n",
        "\n",
        "\n",
        "    def add_conv_layer(self,\n",
        "                       in_channels: int,\n",
        "                       out_channels: int,\n",
        "                       kernel_size: int,\n",
        "                       stride:int) -> None:\n",
        "        \"\"\"\n",
        "        Add a convolutional layer followed by a ReLU activation to the encoder.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_channels : int\n",
        "            The number of input channels.\n",
        "        out_channels : int\n",
        "            The number of output channels.\n",
        "        kernel_size : int\n",
        "            The size of the kernel.\n",
        "        stride : int\n",
        "            The stride of the convolution.\n",
        "        \"\"\"\n",
        "        # Function to add a Convolutional layer followed by a ReLU activation\n",
        "        self.conv_layers.append(nn.Conv1d(in_channels, out_channels, kernel_size, stride))\n",
        "        self.conv_layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the encoder.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The input tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[torch.Tensor, torch.Tensor]\n",
        "            The mean and standard deviation vectors.\n",
        "        \"\"\"\n",
        "\n",
        "        # Pass through each Convolutional layer\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Store the output shape of the last Convolutional layer\n",
        "        self.last_conv_output_shape = x.shape\n",
        "\n",
        "        # Reshape x to match what the multi-head attention layer expects\n",
        "        x = x.permute(2, 0, 1)  # shape becomes (L, N, E)\n",
        "\n",
        "        # Apply self-attention\n",
        "        x, _ = self.self_attention(x, x, x)\n",
        "\n",
        "        # Fully connected layers to output the mean and standard deviation vectors\n",
        "        x = x.mean(dim=0)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self,\n",
        "                       mu: torch.Tensor,\n",
        "                       logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Generate a random sample from the distribution defined by mu and logvar.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : torch.Tensor\n",
        "            The mean vector.\n",
        "        logvar : torch.Tensor\n",
        "            The log variance vector.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The generated sample.\n",
        "        \"\"\"\n",
        "        # Function to generate a random sample from the distribution defined by mu and logvar\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Original inspiration: https://arxiv.org/pdf/2303.07048, credits to Borui Cai, Shuiqiao Yang, Longxiang Gao, Yong Xiang\n",
        "    Implementational changes: LeakyReLU instead of ReLu for conv transpose layers, customized number of layers, upsampling in Decoder.\n",
        "\n",
        "    Decoder class for a Variational Autoencoder (VAE) Neural Network.\n",
        "    Inherits from PyTorch's nn.Module class.\n",
        "\n",
        "    The decoder applies a fully connected layer, an upsample layer, and a series of convolutional transpose layers\n",
        "    to the input from the VAE's latent space.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, latent_dim: int, hidden_dim: int, conv_transpose_filters: Sequence[int],\n",
        "             conv_transpose_kernel_sizes: Sequence[int], conv_transpose_strides: Sequence[int], upsample: int)\n",
        "        Initialize the instance.\n",
        "\n",
        "    add_conv_transpose_layer(self, in_channels, out_channels, kernel_size, stride)\n",
        "        Add a convolutional transpose layer followed by a LeakyReLU activation to the decoder.\n",
        "\n",
        "    forward(self, z) -> torch.Tensor\n",
        "        Forward pass through the decoder.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 latent_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 conv_transpose_filters: Sequence[int],\n",
        "                 conv_transpose_kernel_sizes: Sequence[int],\n",
        "                 conv_transpose_strides: Sequence[int],\n",
        "                 upsample: int) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        latent_dim : int\n",
        "            The dimension of the latent space.\n",
        "        hidden_dim : int\n",
        "            The dimension of the hidden layer.\n",
        "        conv_transpose_filters : Sequence[int]\n",
        "            The number of filters for each convolutional transpose layer.\n",
        "        conv_transpose_kernel_sizes : Sequence[int]\n",
        "            The kernel size for each convolutional transpose layer.\n",
        "        conv_transpose_strides : Sequence[int]\n",
        "            The stride for each convolutional transpose layer.\n",
        "        upsample : int\n",
        "            The scale factor for the upsample layer.\n",
        "        \"\"\"\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Upsample layer\n",
        "        self.upsample = nn.Upsample(scale_factor=upsample)  # adjust this value as needed\n",
        "\n",
        "        # Initialize list for Convolutional Transpose layers\n",
        "        self.conv_transpose_layers = nn.ModuleList()\n",
        "\n",
        "        # Add Convolutional Transpose layers\n",
        "        for i in range(len(conv_transpose_filters)):\n",
        "            self.add_conv_transpose_layer(hidden_dim if i==0 else conv_transpose_filters[i-1],\n",
        "                                          conv_transpose_filters[i], conv_transpose_kernel_sizes[i], conv_transpose_strides[i])\n",
        "\n",
        "    def add_conv_transpose_layer(self,\n",
        "                                 in_channels: int,\n",
        "                                 out_channels: int,\n",
        "                                 kernel_size: int,\n",
        "                                 stride: int) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Add a convolutional transpose layer followed by a LeakyReLU activation to the decoder.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_channels : int\n",
        "            The number of input channels.\n",
        "        out_channels : int\n",
        "            The number of output channels.\n",
        "        kernel_size : int\n",
        "            The size of the kernel.\n",
        "        stride : int\n",
        "            The stride of the convolution transpose.\n",
        "        \"\"\"\n",
        "\n",
        "        # Function to add a Convolutional Transpose layer followed by a ReLU activation\n",
        "        self.conv_transpose_layers.append(nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride))\n",
        "        self.conv_transpose_layers.append(nn.LeakyReLU())\n",
        "\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the decoder.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : torch.Tensor\n",
        "            The input tensor from the VAE's latent space.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output tensor.\n",
        "        \"\"\"\n",
        "        # Fully connected layer\n",
        "        z = F.relu(self.fc(z))\n",
        "\n",
        "        # Reshape to 3D tensor\n",
        "        z = z.view(-1, self.hidden_dim, 1)\n",
        "\n",
        "        # Upsample\n",
        "        z = self.upsample(z)\n",
        "\n",
        "        # Pass through each Convolutional Transpose layer\n",
        "        for layer in self.conv_transpose_layers:\n",
        "            z = layer(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "class HybridVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Original inspiration: https://arxiv.org/pdf/2303.07048, credits to Borui Cai, Shuiqiao Yang, Longxiang Gao, Yong Xiang\n",
        "    Implementational changes: LeakyReLU instead of ReLu for conv transpose layers, customized number of layers, upsampling in Decoder.\n",
        "\n",
        "    Hybrid Variational Autoencoder (VAE) class that combines an encoder and decoder,\n",
        "    inheriting from PyTorch's nn.Module class.\n",
        "\n",
        "    The HybridVAE applies the encoder to the input data to generate a latent representation,\n",
        "    and then applies the decoder to the latent representation to generate the output data.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, input_dim, latent_dim, encoder_params, decoder_params)\n",
        "        Initialize the instance.\n",
        "\n",
        "    forward(self, x) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
        "        Forward pass through the HybridVAE.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 latent_dim: int,\n",
        "                 encoder_params: Sequence[List[int], List[int], List[int], int],\n",
        "                 decoder_params: Sequence[int, List[int],List[int],List[int], int]) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim : int\n",
        "            The dimension of the input data.\n",
        "        latent_dim : int\n",
        "            The dimension of the latent space.\n",
        "        encoder_params : tuple\n",
        "            The parameters for the encoder.\n",
        "        decoder_params : tuple\n",
        "            The parameters for the decoder.\n",
        "        \"\"\"\n",
        "\n",
        "        super(HybridVAE, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(input_dim, *encoder_params, latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, *decoder_params)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass through the HybridVAE.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The input tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
        "            The output from the decoder, and the mean and log variance vectors from the encoder.\n",
        "        \"\"\"\n",
        "\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.encoder.reparameterize(mu, logvar)\n",
        "\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "class Metrics(metaclass=BracketAccess):\n",
        "    \"\"\"\n",
        "    A collection of methods for calculating metrics. The class uses the BracketAccess metaclass\n",
        "    to allow bracket notation for method access.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    mae(y_true, y_pred) -> torch.Tensor\n",
        "        Calculate the Mean Absolute Error (MAE).\n",
        "\n",
        "    mse(y_true, y_pred) -> torch.Tensor\n",
        "        Calculate the Mean Squared Error (MSE).\n",
        "\n",
        "    mase(y_true, y_pred, y_naive) -> torch.Tensor\n",
        "        Calculate the Mean Absolute Scaled Error (MASE).\n",
        "\n",
        "    all() -> List[str]\n",
        "        Get a list of all public methods.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def mae(y_true: torch.Tensor,\n",
        "            y_pred:torch.Tensor,\n",
        "            **kwargs) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate the Mean Absolute Error (MAE).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_true : torch.Tensor\n",
        "            The ground truth tensor.\n",
        "        y_pred : torch.Tensor\n",
        "            The predicted tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The MAE.\n",
        "        \"\"\"\n",
        "        return torch.mean(torch.abs(y_true-y_pred))\n",
        "\n",
        "    @staticmethod\n",
        "    def mse(y_true: torch.Tensor,\n",
        "            y_pred: torch.Tensor,\n",
        "            **kwargs) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate the Mean Squared Error (MSE).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_true : torch.Tensor\n",
        "            The ground truth tensor.\n",
        "        y_pred : torch.Tensor\n",
        "            The predicted tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The MSE.\n",
        "        \"\"\"\n",
        "        return torch.mean((y_true-y_pred)**2)\n",
        "\n",
        "    @staticmethod\n",
        "    def mase(y_true: torch.Tensor,\n",
        "             y_pred: torch.Tensor,\n",
        "             y_naive: torch.Tensor,\n",
        "             **kwargs) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate the Mean Absolute Scaled Error (MASE).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_true : torch.Tensor\n",
        "            The ground truth tensor.\n",
        "        y_pred : torch.Tensor\n",
        "            The predicted tensor.\n",
        "        y_naive : torch.Tensor\n",
        "            The naive forecast.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The MASE.\n",
        "        \"\"\"\n",
        "        mae = Metrics.mae(y_true, y_pred)\n",
        "        scale = Metrics.mae(y_true, y_naive)\n",
        "        return mae/scale\n",
        "\n",
        "    @staticmethod\n",
        "    def all() -> List[str]:\n",
        "        \"\"\"\n",
        "        Get a list of all public methods.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[str]\n",
        "            The list of all public methods.\n",
        "        \"\"\"\n",
        "        return [key for key in Metrics.__dict__.keys() if not key.startswith(\"_\")][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a4d725cd-2020-4eb6-9dc6-9e73f7fff6c3",
      "metadata": {
        "id": "a4d725cd-2020-4eb6-9dc6-9e73f7fff6c3"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "Optimizers = Enum(\"Optimizers\", {\n",
        " 'Adadelta': torch.optim.Adadelta,\n",
        " 'Adagrad': torch.optim.Adagrad,\n",
        " 'Adam': torch.optim.Adam,\n",
        " 'AdamW': torch.optim.AdamW,\n",
        " 'SparseAdam': torch.optim.SparseAdam,\n",
        " 'Adamax': torch.optim.Adamax,\n",
        " 'ASGD': torch.optim.ASGD,\n",
        " 'SGD': torch.optim.SGD,\n",
        " 'RAdam': torch.optim.RAdam,\n",
        " 'Rprop': torch.optim.Rprop,\n",
        " 'RMSprop': torch.optim.RMSprop,\n",
        " 'Optimizer': torch.optim.Optimizer,\n",
        " 'NAdam': torch.optim.NAdam,\n",
        " 'LBFGS': torch.optim.LBFGS,})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "123c740f-f413-4d43-84e4-3d8667c50155",
      "metadata": {
        "id": "123c740f-f413-4d43-84e4-3d8667c50155"
      },
      "outputs": [],
      "source": [
        "from typing import List, Sequence\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "class Reducer:\n",
        "    \"\"\"\n",
        "    Class for training a Variational Autoencoder (VAE) and obtaining the latent representation of a given dataset.\n",
        "\n",
        "    The Reducer applies the fit method to train the VAE, and then applies the latent_rep method to get the latent representation.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, dataset: MultivariateDataset, batch_size: int, optimizer: Literal[...], latent_dim: int,\n",
        "             conv_filters: Sequence[int], conv_kernel_size: Sequence[int], conv_strides: Sequence[int],\n",
        "             attention_heads: int, hidden_dim: int, conv_transpose_filters: Sequence[int],\n",
        "             conv_transpose_kernel_sizes: Sequence[int], conv_transpose_strides: Sequence[int], upsample: int)\n",
        "        Initialize the instance.\n",
        "\n",
        "    loss_hybrid_vae(recon_x, x, mu, logvar) -> torch.Tensor\n",
        "        Calculate the loss of the VAE.\n",
        "\n",
        "    fit(self, epochs: int = 5, metrics: Sequence[str] = None, schedule: bool = False, **kwargs) -> None\n",
        "        Fit the VAE model.\n",
        "\n",
        "    generate(self) -> Sequence\n",
        "        Generate new data.\n",
        "\n",
        "    latent_rep(self, as_numpy: bool = True) -> Sequence\n",
        "        Get the latent representation of the dataset.\n",
        "\n",
        "    decode(latent_rep: List[torch.Tensor]) -> Sequence\n",
        "        Decode the latent representation back to the original space.\n",
        "    \"\"\"\n",
        "    def __new__(cls,\n",
        "                dataset: MultivariateDataset,\n",
        "                batch_size: int,\n",
        "                optimizer: Literal['Adadelta','Adagrad','Adam','AdamW','SparseAdam','Adamax','ASGD','SGD','RAdam','Rprop','RMSprop','Optimizer','NAdam','LBFGS'],\n",
        "                latent_dim: int,\n",
        "                conv_filters: Sequence[int],\n",
        "                conv_kernel_size: Sequence[int],\n",
        "                conv_strides: Sequence[int],\n",
        "                attention_heads: int,\n",
        "                hidden_dim: int,\n",
        "                conv_transpose_filters: Sequence[int],\n",
        "                conv_transpose_kernel_sizes:Sequence[int],\n",
        "                conv_transpose_strides:Sequence[int],\n",
        "                upsample: int):\n",
        "\n",
        "\n",
        "        assert len(conv_filters) == len(conv_kernel_size) == len(conv_strides), AssertionError(\"All encoder arguments have to have same length\")\n",
        "        assert isinstance(dataset, MultivariateDataset), AssertionError(\"Dataset have to be of type MultivariateDataset\")\n",
        "\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataset: MultivariateDataset,\n",
        "                 batch_size: int,\n",
        "                 optimizer: Literal['Adadelta','Adagrad','Adam','AdamW','SparseAdam','Adamax','ASGD','SGD','RAdam','Rprop','RMSprop','Optimizer','NAdam','LBFGS'],\n",
        "                 latent_dim: int,\n",
        "                 conv_filters: Sequence[int],\n",
        "                 conv_kernel_size: Sequence[int],\n",
        "                 conv_strides: Sequence[int],\n",
        "                 attention_heads: int,\n",
        "                 hidden_dim: int,\n",
        "                 conv_transpose_filters: Sequence[int],\n",
        "                 conv_transpose_kernel_sizes:Sequence[int],\n",
        "                 conv_transpose_strides:Sequence[int],\n",
        "                 upsample: int) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : MultivariateDataset\n",
        "            The dataset to reduce.\n",
        "        batch_size : int\n",
        "            The size of the batches for training.\n",
        "        optimizer : Literal[...]\n",
        "            The optimizer to use for training.\n",
        "        latent_dim : int\n",
        "            The dimension of the latent space.\n",
        "        conv_filters : Sequence[int]\n",
        "            The number of filters for each convolutional layer in the encoder.\n",
        "        conv_kernel_size : Sequence[int]\n",
        "            The kernel size for each convolutional layer in the encoder.\n",
        "        conv_strides : Sequence[int]\n",
        "            The stride for each convolutional layer in the encoder.\n",
        "        attention_heads : int\n",
        "            The number of attention heads for the multi-head self-attention mechanism in the encoder.\n",
        "        hidden_dim : int\n",
        "            The dimension of the hidden layer in the decoder.\n",
        "        conv_transpose_filters : Sequence[int]\n",
        "            The number of filters for each convolutional transpose layer in the decoder.\n",
        "        conv_transpose_kernel_sizes : Sequence[int]\n",
        "            The kernel size for each convolutional transpose layer in the decoder.\n",
        "        conv_transpose_strides : Sequence[int]\n",
        "            The stride for each convolutional transpose layer in the decoder.\n",
        "        upsample : int\n",
        "            The scale factor for the upsample layer in the decoder.\n",
        "        \"\"\"\n",
        "\n",
        "        global DEVICE\n",
        "\n",
        "        self.data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "        self.model = HybridVAE(input_dim=dataset.tensors.shape[1],\n",
        "                               latent_dim=latent_dim,\n",
        "                               encoder_params=(conv_filters, conv_kernel_size, conv_strides, attention_heads),\n",
        "                               decoder_params=(hidden_dim, conv_transpose_filters,\n",
        "                                               conv_transpose_kernel_sizes, conv_transpose_strides,\n",
        "                                               upsample)).to(DEVICE)\n",
        "        self.optimizer = Optimizers[optimizer].value(params=self.model.parameters())\n",
        "\n",
        "    @staticmethod\n",
        "    def loss_hybrid_vae(recon_x: torch.Tensor,\n",
        "                        x: torch.Tensor,\n",
        "                        mu: torch.Tensor,\n",
        "                        logvar:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate the loss of the VAE.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        recon_x : torch.Tensor\n",
        "            The reconstructed tensor.\n",
        "        x : torch.Tensor\n",
        "            The original input tensor.\n",
        "        mu : torch.Tensor\n",
        "            The mean vector.\n",
        "        logvar : torch.Tensor\n",
        "            The log variance vector.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The computed loss.\n",
        "        \"\"\"\n",
        "        # Reconstruction loss\n",
        "        recon_loss = F.mse_loss(recon_x, x)\n",
        "\n",
        "        # KL divergence loss\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        # Total loss\n",
        "        loss = recon_loss + kl_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self,\n",
        "            epochs: int = 5,\n",
        "            metrics: None | Literal['mse','mase','mae'] = None,\n",
        "            schedule: bool = False,\n",
        "            **kwargs) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Fit the VAE model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        epochs : int, optional\n",
        "            The number of epochs to train for. Default is 5.\n",
        "        metrics :  None | Literal['mse','mase','mae']\n",
        "            The metrics to compute during training. Default is None.\n",
        "        schedule : bool, optional\n",
        "            Whether to use a learning rate scheduler. Default is False.\n",
        "        **kwargs\n",
        "            Additional keyword arguments, accordingly to provided metrics\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "\n",
        "        if metrics != None:\n",
        "            assert hasattr(metrics, \"__iter__\"), AssertionError('If not none, metrics have to be iterable object')\n",
        "            for name in metrics:\n",
        "                assert name in Metrics.all(), AssertionError(f\"{name} must be one of {Metrics.all()}.\")\n",
        "\n",
        "\n",
        "        desc = \"Fitting VAE model on dataset...\"\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in tqdm(range(epochs), total=epochs, desc=desc):\n",
        "            summary = {'epoch':epoch+1}\n",
        "            for batch in self.data_loader:\n",
        "                x = batch\n",
        "                self.optimizer.zero_grad()\n",
        "                recon_x, mu, logvar = self.model(x)\n",
        "                loss = Reducer.loss_hybrid_vae(recon_x, x, mu, logvar)\n",
        "                summary['loss'] = loss.item() #.:4f\n",
        "                if metrics is not None:\n",
        "                    for name in metrics:\n",
        "                        summary[name] = Metrics[name](recon_x, x, **kwargs).item() #:.4f\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            print(summary)\n",
        "\n",
        "            if schedule:\n",
        "                scheduler.step(loss)\n",
        "\n",
        "    def generate(self) -> Sequence:\n",
        "        \"\"\"\n",
        "        NOT IMPLEMENTED YET\n",
        "\n",
        "        Generate new data.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Sequence\n",
        "            The generated data.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def latent_rep(self, as_numpy: bool = True) -> Sequence:\n",
        "\n",
        "        \"\"\"\n",
        "        Get the latent representation of the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        as_numpy : bool, optional\n",
        "            Whether to return the latent representation as a NumPy array. Default is True.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Sequence\n",
        "            The latent representation.\n",
        "        \"\"\"\n",
        "\n",
        "        encoded = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.data_loader):\n",
        "                x = batch\n",
        "                mu, logvar = self.model.encoder(x)\n",
        "                z = self.model.encoder.reparameterize(mu, logvar)\n",
        "                encoded.append(z)\n",
        "\n",
        "        if as_numpy:\n",
        "            return np.vstack([item.cpu().numpy() for item in encoded])\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, latent_rep: List[torch.Tensor]) -> Sequence:\n",
        "        \"\"\"\n",
        "        Decode the latent representation back to the original space.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        latent_rep : List[torch.Tensor]\n",
        "            The latent representation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Sequence\n",
        "            The decoded data.\n",
        "        \"\"\"\n",
        "\n",
        "        return [self.model.decoder(entry) for entry in latent_rep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e5810d6c-7921-4ad6-8df1-ccf878734bd3",
      "metadata": {
        "id": "e5810d6c-7921-4ad6-8df1-ccf878734bd3"
      },
      "outputs": [],
      "source": [
        "CONV_FILTERS = [64,128]\n",
        "EXAMPLE_PARAMS = {'dataset': SAMPLE_DATASET,\n",
        "                 'batch_size': 32,\n",
        "                 'optimizer': 'Adam',\n",
        "                 'latent_dim': 1000,\n",
        "                 'conv_filters': CONV_FILTERS,\n",
        "                 'conv_kernel_size': [3,3],\n",
        "                 'conv_strides': [2,2],\n",
        "                 'attention_heads':8,\n",
        "                 'hidden_dim': 400,\n",
        "                 'conv_transpose_filters': [128,9],\n",
        "                 'conv_transpose_kernel_sizes': [2,2],\n",
        "                 'conv_transpose_strides': [2,2],\n",
        "                 'upsample': SAMPLE_DATASET.tensors.shape[-1]/(len(CONV_FILTERS)*2)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f9019863-63f1-48cd-b1a8-6e26b8a9399f",
      "metadata": {
        "id": "f9019863-63f1-48cd-b1a8-6e26b8a9399f"
      },
      "outputs": [],
      "source": [
        "r = Reducer(**EXAMPLE_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c0b9f1d6-05f4-40bd-ae21-63e0d4dda41e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75,
          "referenced_widgets": [
            "006d1601be0042efa4a75611e4b3dcb7",
            "fd8914ff6b174b088cb04b131b33aa55",
            "33ccb93c9a9a4ad199ed23a0ad56133b",
            "f5fb01db71e7495ab6a67a74b8e3f286",
            "82fa159f805046679ff7293dd3d48efa",
            "adc009537a7749008f9655aa91f62bf5",
            "9ef54541e252445cbd539868e54f17d1",
            "6e2463ec0e2b44bd91da5a8a8e6c339a",
            "e5e84b97d3bf497f9ba55f40978f8861",
            "a4f1492bc84841c78cebb98e7a42d4d0",
            "568e5ca6b7774ca9987baf8798d800bb"
          ]
        },
        "id": "c0b9f1d6-05f4-40bd-ae21-63e0d4dda41e",
        "outputId": "c9c123e7-484c-45aa-cd44-7ff5b84f25eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fitting VAE model on dataset...:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "006d1601be0042efa4a75611e4b3dcb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'loss': 3.5566868782043457, 'mae': 0.7161697149276733, 'mse': 0.7628805041313171}\n"
          ]
        }
      ],
      "source": [
        "r.fit(epochs=1, metrics=['mae','mse'], schedule=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2d9037f3-80bc-49f7-932e-df3cb92a2872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "cd9b903786de454a8d371b6ab7b91c88",
            "5e59c21c092c41e98d0af7d124887d33",
            "89dd376a8a5143c4a5a8f87f765022b0",
            "5dd0f5dd6b794de998171eb22f29b0a0",
            "9a8c555c2bfa45a7b836e7de030a2403",
            "8db8c68bff794970b66b1145744be0f7",
            "3b20d1d5d0374d99a971bbbf8746cecd",
            "6aec720963304ae48b684e3beeacfeb2",
            "98b8c2e2e09643d1b1604b138c7b4b0e",
            "13a410bf94ad47dca06acc10df9379ef",
            "aac057e05c8b43ac8c1e25486eada3ff"
          ]
        },
        "id": "2d9037f3-80bc-49f7-932e-df3cb92a2872",
        "outputId": "cac92dd4-1378-4525-a966-32083253556d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd9b903786de454a8d371b6ab7b91c88"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "rep = r.latent_rep()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "ddf51481-920a-48d9-8317-1b038d887df2",
      "metadata": {
        "id": "ddf51481-920a-48d9-8317-1b038d887df2"
      },
      "outputs": [],
      "source": [
        "class Clusters:\n",
        "    \"\"\"\n",
        "    Class for generating clusters of a given latent representation of an initial dataset.\n",
        "\n",
        "    The Clusters class applies the fit method to train the clustering model (using the k-means algorithm),\n",
        "    and then applies the get method to obtain the clusters.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, latent_rep: np.ndarray, gpu: bool = False)\n",
        "        Initialize the instance.\n",
        "\n",
        "    get(self, k:int, n_iter: int, seed: int = np.random.choice(9999))\n",
        "        Obtain the clusters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 latent_rep: np.ndarray,\n",
        "                 gpu: bool = False) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        latent_rep : np.ndarray\n",
        "            The latent representation of the dataset.\n",
        "        gpu : bool, optional\n",
        "            Whether to use GPU. Default is False.\n",
        "        \"\"\"\n",
        "\n",
        "        # initialize\n",
        "        faiss.normalize_L2(latent_rep)\n",
        "\n",
        "        self.latent = latent_rep\n",
        "        self.index = faiss.IndexFlatL2(self.latent.shape[1])\n",
        "        self.gpu = gpu\n",
        "\n",
        "        if self.gpu:\n",
        "            res = faiss.StandardGpuResources()\n",
        "            self.index = faiss.index_cpu_to_gpu(res, 0, self.index)\n",
        "\n",
        "\n",
        "    def get(self,\n",
        "            k:int,\n",
        "            n_iter: int,\n",
        "            seed: int = np.random.choice(9999)) -> faiss.Kmeans:\n",
        "\n",
        "        \"\"\"\n",
        "        Obtain the clusters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k : int\n",
        "            The number of clusters.\n",
        "        n_iter : int\n",
        "            The number of iterations for k-means.\n",
        "        seed : int, optional\n",
        "            The seed for random number generation. Default is a random number between 0 and 9999.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        faiss.Kmeans\n",
        "            The trained k-means model.\n",
        "        \"\"\"\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        kmeans = faiss.Kmeans(d=self.latent.shape[1],\n",
        "                              k=k,\n",
        "                              niter=n_iter,\n",
        "                              gpu=self.gpu)\n",
        "\n",
        "        kmeans.train(self.latent)\n",
        "\n",
        "        return kmeans\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis, moment"
      ],
      "metadata": {
        "id": "Lmi7mLuIPpXe"
      },
      "id": "Lmi7mLuIPpXe",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from dataclasses import dataclass\n",
        "from typing import Union, Sequence, Tuple, Dict\n",
        "\n",
        "class SingleCluster:\n",
        "    \"\"\"\n",
        "    Class that stores and computes data about a single k-means cluster.\n",
        "\n",
        "    The SingleCluster class computes statistics about the cluster's centroid and provides a method to visualize its distribution.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, cluster: int, centroid: np.ndarray, idxs: np.ndarray, subset: np.ndarray)\n",
        "        Initialize the instance.\n",
        "\n",
        "    __calc_data_stats(self, centroid) -> Tuple\n",
        "        Calculate statistics about the centroid.\n",
        "\n",
        "    plot(self)\n",
        "        Plot a histogram of the centroid.\n",
        "\n",
        "    __getitem__(self, key: str)\n",
        "        Get the value of an attribute.\n",
        "\n",
        "    __repr__(self)\n",
        "        Get a string representation of the instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 cluster: int,\n",
        "                 centroid: np.ndarray,\n",
        "                 idxs: np.ndarray,\n",
        "                 subset: np.ndarray) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cluster : int\n",
        "            The cluster number.\n",
        "        centroid : np.ndarray\n",
        "            The centroid of the cluster.\n",
        "        idxs : np.ndarray\n",
        "            The indices of the elements in the cluster.\n",
        "        subset : np.ndarray\n",
        "            The subset of the data in the cluster.\n",
        "        \"\"\"\n",
        "\n",
        "        self.cluster = cluster\n",
        "        self.idxs = idxs\n",
        "        self.n_elements = len(subset)\n",
        "        self.centroid = centroid\n",
        "        self.mean, self.std, self.skew, self.kutosis, self.moment = self.__calc_data_stats(subset)\n",
        "        self.subset = subset\n",
        "\n",
        "    def __calc_data_stats(self, centroid) -> Tuple:\n",
        "\n",
        "        \"\"\"\n",
        "        Calculate statistics about the centroid.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        centroid : np.ndarray\n",
        "            The centroid of the cluster.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple\n",
        "            The mean, standard deviation, skewness, kurtosis, and nth moment of the centroid.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        skew_ = skew(centroid)\n",
        "        kurtosis_ = kurtosis(centroid)\n",
        "        moment_ = moment(centroid)\n",
        "        mean_ = centroid.mean(axis=0).mean()\n",
        "        std_ = centroid.mean(axis=0).std()\n",
        "\n",
        "        return mean_, std_, skew_, kurtosis_, moment_\n",
        "\n",
        "    def plot(self) -> None:\n",
        "        \"\"\"\n",
        "        Plot a histogram of the centroid.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "        plt.figure()\n",
        "        plt.title(self.cluster)\n",
        "        plt.hist(self.centroid,\n",
        "                 color='orange',\n",
        "                 label='Centroid values', alpha=0.6,)\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def __getitem__(self, key: str):\n",
        "        \"\"\"\n",
        "        Get the value of an attribute.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        key : str\n",
        "            The attribute to get the value of.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Any\n",
        "            The value of the attribute.\n",
        "        \"\"\"\n",
        "        return getattr(self, str(key), None)\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Get a string representation of the instance.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representation of the instance.\n",
        "        \"\"\"\n",
        "        keys = ['n_elements', 'mean', 'std', 'skew', 'kurtosis', 'moment']\n",
        "        vals = [self[key] for key in keys]\n",
        "        name = self.__class__.__name__\n",
        "        sufix = \", \".join([\"=\".join([k,str(v)]) for k,v in zip(keys, vals)])\n",
        "\n",
        "        return f\"{name}[{self.cluster}]({sufix})\"\n",
        "\n",
        "\n",
        "\n",
        "class ClustersDescription:\n",
        "    \"\"\"\n",
        "    Class that describes a k-means object given by the Clusters.get() method.\n",
        "\n",
        "    The ClustersDescription class provides details about the k-means clusters including their centroids, indices,\n",
        "    and a subset of data in each cluster.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self, kmeans: faiss.Kmeans, latent: np.ndarray) -> None\n",
        "        Initialize the instance.\n",
        "\n",
        "    __getitem__(self, index: Union[int, str])\n",
        "        Get a specific cluster.\n",
        "\n",
        "    __len__(self)\n",
        "        Get the number of clusters.\n",
        "\n",
        "    __repr__(self)\n",
        "        Get a string representation of the instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kmeans: faiss.Kmeans, latent: np.ndarray) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the instance.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        kmeans : faiss.Kmeans\n",
        "            The k-means model.\n",
        "        latent : np.ndarray\n",
        "            The latent representation of the dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        self.proba, self.index = [a.flatten() for a in kmeans.index.search(latent, 1)]\n",
        "\n",
        "        for cluster in np.unique(self.index):\n",
        "            centroid = kmeans.centroids[cluster]\n",
        "            idxs = np.argwhere(self.index == cluster).flatten()\n",
        "            sub = latent[idxs]\n",
        "            setattr(self, str(cluster), SingleCluster(cluster, centroid, idxs, sub))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: Union[int, str]):\n",
        "        \"\"\"\n",
        "        Get a specific cluster.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        index : Union[int, str]\n",
        "            The index or name of the cluster to get.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Any\n",
        "            The cluster object.\n",
        "        \"\"\"\n",
        "        return getattr(self, str(index), None)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the number of clusters.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            The number of clusters.\n",
        "        \"\"\"\n",
        "        return len(np.unique(self.index))\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Get a string representation of the instance.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representation of the instance.\n",
        "        \"\"\"\n",
        "        name = self.__class__.__name__\n",
        "        return f\"{name}(n_clusters={len(self)})\""
      ],
      "metadata": {
        "id": "ReJnfsxTKsTs"
      },
      "id": "ReJnfsxTKsTs",
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDnGU30cHg0S"
      },
      "id": "iDnGU30cHg0S",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006d1601be0042efa4a75611e4b3dcb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd8914ff6b174b088cb04b131b33aa55",
              "IPY_MODEL_33ccb93c9a9a4ad199ed23a0ad56133b",
              "IPY_MODEL_f5fb01db71e7495ab6a67a74b8e3f286"
            ],
            "layout": "IPY_MODEL_82fa159f805046679ff7293dd3d48efa"
          }
        },
        "fd8914ff6b174b088cb04b131b33aa55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc009537a7749008f9655aa91f62bf5",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef54541e252445cbd539868e54f17d1",
            "value": "Fitting VAE model on dataset...: 100%"
          }
        },
        "33ccb93c9a9a4ad199ed23a0ad56133b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2463ec0e2b44bd91da5a8a8e6c339a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5e84b97d3bf497f9ba55f40978f8861",
            "value": 1
          }
        },
        "f5fb01db71e7495ab6a67a74b8e3f286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f1492bc84841c78cebb98e7a42d4d0",
            "placeholder": "​",
            "style": "IPY_MODEL_568e5ca6b7774ca9987baf8798d800bb",
            "value": " 1/1 [00:59&lt;00:00, 59.63s/it]"
          }
        },
        "82fa159f805046679ff7293dd3d48efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc009537a7749008f9655aa91f62bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef54541e252445cbd539868e54f17d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e2463ec0e2b44bd91da5a8a8e6c339a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e84b97d3bf497f9ba55f40978f8861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4f1492bc84841c78cebb98e7a42d4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568e5ca6b7774ca9987baf8798d800bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd9b903786de454a8d371b6ab7b91c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e59c21c092c41e98d0af7d124887d33",
              "IPY_MODEL_89dd376a8a5143c4a5a8f87f765022b0",
              "IPY_MODEL_5dd0f5dd6b794de998171eb22f29b0a0"
            ],
            "layout": "IPY_MODEL_9a8c555c2bfa45a7b836e7de030a2403"
          }
        },
        "5e59c21c092c41e98d0af7d124887d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db8c68bff794970b66b1145744be0f7",
            "placeholder": "​",
            "style": "IPY_MODEL_3b20d1d5d0374d99a971bbbf8746cecd",
            "value": "100%"
          }
        },
        "89dd376a8a5143c4a5a8f87f765022b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aec720963304ae48b684e3beeacfeb2",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98b8c2e2e09643d1b1604b138c7b4b0e",
            "value": 26
          }
        },
        "5dd0f5dd6b794de998171eb22f29b0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a410bf94ad47dca06acc10df9379ef",
            "placeholder": "​",
            "style": "IPY_MODEL_aac057e05c8b43ac8c1e25486eada3ff",
            "value": " 26/26 [00:21&lt;00:00,  1.25it/s]"
          }
        },
        "9a8c555c2bfa45a7b836e7de030a2403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db8c68bff794970b66b1145744be0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b20d1d5d0374d99a971bbbf8746cecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aec720963304ae48b684e3beeacfeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b8c2e2e09643d1b1604b138c7b4b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a410bf94ad47dca06acc10df9379ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac057e05c8b43ac8c1e25486eada3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}